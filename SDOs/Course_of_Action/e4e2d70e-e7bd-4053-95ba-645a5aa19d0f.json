{
    "type": "course-of-action",
    "spec_version": "2.1",
    "id": "course-of-action--e4e2d70e-e7bd-4053-95ba-645a5aa19d0f",
    "created": "2024-08-14T07:36:37.584861Z",
    "modified": "2024-08-14T07:36:37.584861Z",
    "name": "Transformer-XL",
    "description": "Transformer-XL is a transformer architecture that introduces the notion of recurrence to the deep self-attention network. Instead of computing the hidden states from scratch for each new segment, Transformer-XL reuses the hidden states obtained in previous segments.",
    "x_d3fend_id": "D3A-TX",
    "x_kb_article": "## References\nTransformer-XL. (n.d.). Papers with Code. [Link](https://paperswithcode.com/method/transformer-xl)"
}