{
    "type": "course-of-action",
    "spec_version": "2.1",
    "id": "course-of-action--36523f37-8de2-43e9-8200-64445b1c1d7d",
    "created": "2024-08-14T07:36:36.895972Z",
    "modified": "2024-08-14T07:36:36.895972Z",
    "name": "BERT",
    "description": "Bidirectional Encoder Representations from Transformers (BERT) is based on a deep learning model in which every output element is connected to every input element, and the weightings between them are dynamically calculated based upon their connection.",
    "x_d3fend_id": "D3A-BER",
    "x_kb_article": "## References\nBERT (language model). (n.d.). In TechTarget. [Link](https://www.techtarget.com/searchenterpriseai/definition/BERT-language-model)\nBERT (language model). (n.d.). In Wikipedia. [Link](https://en.wikipedia.org/wiki/BERT_(language_model))",
    "x_synonym": "Bidirectional Encoder Representations from Transformers"
}