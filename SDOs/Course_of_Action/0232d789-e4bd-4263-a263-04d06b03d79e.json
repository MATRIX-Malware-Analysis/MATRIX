{
    "type": "course-of-action",
    "spec_version": "2.1",
    "id": "course-of-action--0232d789-e4bd-4263-a263-04d06b03d79e",
    "created": "2024-08-14T07:36:37.290335Z",
    "modified": "2024-08-14T07:36:37.290335Z",
    "name": "Model-free Reinforcement Learning",
    "description": "In reinforcement learning (RL), a model-free algorithm (as opposed to a model-based one) is an algorithm which does not use the transition probability distribution (and the reward function) associated with the Markov decision process (MDP),which, in RL, represents the problem to be solved. The transition probability distribution (or transition model) and the reward function are often collectively called the \"model\" of the environment (or MDP), hence the name \"model-free\". A model-free RL algorithm can be thought of as an \"explicit\" trial-and-error algorithm. An example of a model-free algorithm is Q-learning.",
    "x_d3fend_id": "D3A-MFRL",
    "x_kb_article": "## References\nModel-free (reinforcement learning). Wikipedia. [Link](https://en.wikipedia.org/wiki/Model-free_(reinforcement_learning)).)"
}