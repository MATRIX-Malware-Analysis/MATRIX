{
    "type": "course-of-action",
    "spec_version": "2.1",
    "id": "course-of-action--265a5042-b32a-451c-bacc-0cb0dc1a891e",
    "created": "2024-08-14T07:36:35.190672Z",
    "modified": "2024-08-14T07:36:35.190672Z",
    "name": "Transformer-XL",
    "description": "Transformer-XL is a transformer architecture that introduces the notion of recurrence to the deep self-attention network. Instead of computing the hidden states from scratch for each new segment, Transformer-XL reuses the hidden states obtained in previous segments.",
    "x_d3fend_id": "D3A-TX",
    "x_kb_article": "## References\nTransformer-XL. (n.d.). Papers with Code. [Link](https://paperswithcode.com/method/transformer-xl)"
}