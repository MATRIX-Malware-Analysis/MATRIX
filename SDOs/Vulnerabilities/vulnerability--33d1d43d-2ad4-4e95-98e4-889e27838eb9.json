{
    "type": "vulnerability",
    "spec_version": "2.1",
    "id": "vulnerability--33d1d43d-2ad4-4e95-98e4-889e27838eb9",
    "created": "2024-08-13T16:08:09.883998Z",
    "modified": "2024-08-13T16:08:09.884002Z",
    "name": "Segfault in `QuantizedRelu` and `QuantizedRelu6`",
    "description": "TensorFlow is an open source platform for machine learning. If `QuantizedRelu` or `QuantizedRelu6` are given nonscalar inputs for `min_features` or `max_features`, it results in a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 49b3824d83af706df0ad07e4e677d88659756d89. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
    "external_references": [
        {
            "source_name": "cve",
            "external_id": "CVE-2022-35979"
        }
    ],
    "metrics": [
        {
            "cvssV3_1": {
                "attackComplexity": "HIGH",
                "attackVector": "NETWORK",
                "availabilityImpact": "HIGH",
                "baseScore": 5.9,
                "baseSeverity": "MEDIUM",
                "confidentialityImpact": "NONE",
                "integrityImpact": "NONE",
                "privilegesRequired": "NONE",
                "scope": "UNCHANGED",
                "userInteraction": "NONE",
                "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H",
                "version": "3.1"
            }
        }
    ],
    "references": [
        {
            "tags": [
                "x_refsource_MISC"
            ],
            "url": "https://github.com/tensorflow/tensorflow/commit/49b3824d83af706df0ad07e4e677d88659756d89"
        },
        {
            "tags": [
                "x_refsource_CONFIRM"
            ],
            "url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v7vw-577f-vp8x"
        }
    ]
}